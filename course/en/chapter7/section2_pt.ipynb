{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BrigpkgRW2Q"
      },
      "source": [
        "# Token classification (PyTorch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKdGmqqDRW2T"
      },
      "source": [
        "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYplK8eRRW2U"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]\n",
        "!pip install accelerate\n",
        "# To run the training on TPU, you will need to uncomment the following line:\n",
        "# !pip install cloud-tpu-client==0.10 torch==1.9.0 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n",
        "!apt install git-lfs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9-SqDxVRW2W"
      },
      "source": [
        "You will need to setup git, adapt your email and name in the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcPMZSehRW2X"
      },
      "outputs": [],
      "source": [
        "!git config --global user.email \"you@example.com\"\n",
        "!git config --global user.name \"Your Name\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCC_cGbiRW2X"
      },
      "source": [
        "You will also need to be logged in to the Hugging Face Hub. Execute the following and enter your credentials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359,
          "referenced_widgets": [
            "a2b84a857df94bb8942a0d70e7f0200e",
            "6acf492ce2ae490bb36d617a4238ab08",
            "5155c91eca814b0096b830c28dbe776a",
            "d7cf306a74d94b49938d3b7c25e51761",
            "8a3f69f5c7d841a099ad1a2fbe41b9b5",
            "61f0490a891f4afa8642e0394fa46c78",
            "ea9afcb1a1f049309394ee2de9115106",
            "b0e3232024224a77a04b4af6c3ddb76a",
            "c6e22ef7fbfb4d4b99d05d7650dfa863",
            "b1ba352d2da2463a9e98ae83a1771490",
            "d7b2e759cc0240ffb32b41fc45e15517",
            "f6cab106d974494c95f86088fa732a24",
            "78341da8e9d84c308584ad66fc6dac9a",
            "40682fa762d1426fb5d9673e5a51aee4",
            "d585d81bd43b4c7493623dbc9bdf923a",
            "890c59a42ced441798f40e8dd50c782f",
            "c958832bc7da42b8b11ff05908dbe6df"
          ]
        },
        "id": "ZCD-_QsDRW2Y",
        "outputId": "7482fdfb-2084-478a-bff7-7361ab9eca9b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2b84a857df94bb8942a0d70e7f0200e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the data"
      ],
      "metadata": {
        "id": "PgVtcBoUT5Fo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First things first, we need a dataset suitable for token classification. In this section we will use the CoNLL-2003 dataset, which contains news stories from Reuters."
      ],
      "metadata": {
        "id": "oFCUZrDCUDi_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The CoNLL-2003 dataset"
      ],
      "metadata": {
        "id": "S9vusSM0UQIN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To load the CoNLL-2003 dataset, we use the load_dataset() method from the ðŸ¤— Datasets library:"
      ],
      "metadata": {
        "id": "Xtk6W3xQUQ7y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365,
          "referenced_widgets": [
            "2f8f6a83873945e29f626f77fcfaa380",
            "f9846296a212422c9bd87c2261114557",
            "5b2bbff92e7c47ddad7e670a6348e918",
            "74c1affa057c42d3881b5716a9c54200",
            "ff3bdd8f852e4a0c9870f23a98c95a1a",
            "bd9f1e216e56475aab19e558b2b602be",
            "c9080856037445e485b4c7f5d42f6136",
            "835e414f1c644ce3b1fa9511167d5f0f",
            "4f06e3ac00fb498d935e2e4a8c044be6",
            "b92d03ad67d24e73ae01b8501e0b464e",
            "eaa97267ac544b01b5d538baf46f255c",
            "efdab11161c5437898578847efd67b90",
            "3d3ec5d20b2d4251825f46dbe8c672d2",
            "e941d91a37bd45ca8f7d60c617bd9665",
            "afe7a55c548441968e398d8cc1bf39ad",
            "0c6220cafd784792ac86823d5c9061bb",
            "04d731b0ca5c4ea5b5643c3162da20c6",
            "a9867688eb5b4cc081759eb685c05c3d",
            "cfb5fb5745a548f6bbc1b022ddaf5dd5",
            "05ff7ec50b894373ae356a6f27eca02a",
            "1e95000e83bc4152b8cb1b3955de06c0",
            "7395b6d49d154ab09d12a0eb529784f7",
            "287a4dca75704d0c94a431ab1cd8fd14",
            "4e03656bfa7749c0adf1a70212fc055f",
            "5b59f0b7976241ec975ac0cdf50d43c4",
            "274323aa0a8b47689a9487c042af4a43",
            "badb09f0c36b419b94a44c6c21e24a43",
            "ac78f53623e0497583fef9a59222025c",
            "d80d0c03b4954024be2b1a8243620d7d",
            "0b9866c4f65b4b389720b6dc218c93f5",
            "50d7907623d349298f4d1d3b2817f1e3",
            "3d29494f97af4f55be19d879c7ee3979",
            "b29d79b8cbc1440a8bb53a59fc11d9c5",
            "1f87d603cd0c486981acf2e658719eba",
            "3bc2fd0ffa7049e6a48f4e61ca6d5433",
            "2ee1ae10e455493997740de43abe063d",
            "b2653a817169421aa13a471c7b132ba0",
            "60bf5e52eefc49658c2305843735dbb7",
            "5642ff8cc2904471b7d09ff3728ce07f",
            "f470c5069ae543689ce4ce3671e02dcf",
            "c2b03bf9fbcf4f6d8c719a012841b18d",
            "db6943acf0b94a3dbb9983ecfd8c6c18",
            "add9ef7946d54ae5a537cbbbff1c9065",
            "dbeb483b63f74f4e92b1aa4e31e39ead",
            "6e6a34f2c2434051bde7ccd7b0d305db",
            "c00f625154f049a88d1427845d9f03ae",
            "c202d98ec3564b74a32de6fc8b0925ec",
            "878a2e7de35f4259823736920a893d04",
            "8b28d369a3774aec9313e1c86a9d69fb",
            "75d4e6318e694db7b57e4295ea1debe9",
            "c2cbea16e99b4094bc1c755b92b15cc0",
            "145efaf5dfb6448ca0a267cfd9588730",
            "01c4b56a88264d17a8eb87c5c8ce46d0",
            "16bef6bf18104b0eb3b7635998d0285d",
            "8208c16320c248ad99f7a37c915eb45c",
            "d7762743dba44fb89a9662fc85cd87ae",
            "26701ca18bd5486bbe3f8bd87aeac435",
            "22e8fa0c61c94d569e2f5003786db215",
            "f0957b993b314613a4a2e3cd83eef05d",
            "2677d81dda244e43b75567375396eacf",
            "023818358cac493c9ad2bae7819eb858",
            "954ea0c2eb404deea519829e5c434801",
            "58e475aaef57470aa9f1209d8c672668",
            "8bf0f6cbfd984b58ac43d80f66f5afeb",
            "5408cfed6a9b49fb8f6b976c9c2abf49",
            "91243ea0ae9a4be3bce0baca656126df",
            "3dc20da716384ba08641b93e42d7d5f7",
            "75ea55f3ebc64a0fa8d45b462e4c2bb4",
            "5deaf465f552402ebc29efb5252f5de5",
            "242faf961d5147e29dc25aee400d11de",
            "2966463ea60142b18f651eb43b4a87b3",
            "a4c2f633e95f4499aca3b9ad97d6e08a",
            "e78b38523a7b4aabac0251003326c181",
            "d1b07495e0724cdfbd1473c91f2ed266",
            "17536abd31044b68902385739efaae34",
            "c852fa204a604074a7e0210dc0a827cc",
            "dfe1ee3e47d0408eb8af961e3384cd83"
          ]
        },
        "id": "sH6B8gp0RW2Z",
        "outputId": "9446cfc4-73fc-4826-c49b-50ee9ae0983b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "dataset_infos.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f8f6a83873945e29f626f77fcfaa380"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00000-of-00001.parquet:   0%|          | 0.00/1.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efdab11161c5437898578847efd67b90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/validation-00000-of-00001.parquet:   0%|          | 0.00/281k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "287a4dca75704d0c94a431ab1cd8fd14"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/test-00000-of-00001.parquet:   0%|          | 0.00/259k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f87d603cd0c486981acf2e658719eba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/14041 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e6a34f2c2434051bde7ccd7b0d305db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/3250 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7762743dba44fb89a9662fc85cd87ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/3453 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3dc20da716384ba08641b93e42d7d5f7"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# raw_datasets = load_dataset(\"conll2003\")\n",
        "raw_datasets = load_dataset(\"lhoestq/conll2003\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will download and cache the dataset, like previous chapter (in Chapter 3) for the GLUE MRPC dataset. Inspecting this object shows us the columns present and the split between the training, validation, and test sets:"
      ],
      "metadata": {
        "id": "TjMnWLzZUdEw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMEjqHERRW2a",
        "outputId": "6847a359-6032-406e-9117-7b7fb2ec4352"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 14041\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3250\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3453\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "raw_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In particular, we can see the dataset contains labels for the three tasks we mentioned earlier: NER, POS, and chunking. A big difference from other datasets is that the input texts are not presented as sentences or documents, but lists of words (the last column is called tokens, but it contains words in the sense that these are pre-tokenized inputs that still need to go through the tokenizer for subword tokenization).\n",
        "\n",
        "Letâ€™s have a look at the first element of the training set:"
      ],
      "metadata": {
        "id": "Mpsr-t7SUvCk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdD3uB41RW2c",
        "outputId": "a2724382-f04f-40a9-8495-1c8242b18716"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "raw_datasets[\"train\"][0][\"tokens\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we want to perform named entity recognition, we will look at the NER tags:"
      ],
      "metadata": {
        "id": "zPyIBOqsU25k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3F-DcLjRW2d",
        "outputId": "9a107a6f-b5ef-4136-aa88-0d78e85684f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 0, 7, 0, 0, 0, 7, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "raw_datasets[\"train\"][0][\"ner_tags\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Those are the labels as integers ready for training, but theyâ€™re not necessarily useful when we want to inspect the data. Like for text classification, we can access the correspondence between those integers and the label names by looking at the features attribute of our dataset:"
      ],
      "metadata": {
        "id": "V53R4A_YU-Ap"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWXTsF-uRW2d",
        "outputId": "0b728ec1-c0fb-47e8-8006-885bc25ce4b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "List(Value('int64'))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "ner_feature = raw_datasets[\"train\"].features[\"ner_tags\"]\n",
        "ner_feature"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import ClassLabel, Sequence\n",
        "# There need to cast the numberic representation of the features to labels.\n",
        "Sequence(feature=ClassLabel(num_classes=9, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], names_file=None, id=None), length=-1, id=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8A6VwgZI72A",
        "outputId": "faefe0ed-5f08-4690-a134-ddde9566df91"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "List(ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So this column contains elements that are sequences of ClassLabels. The type of the elements of the sequence is in the feature attribute of this ner_feature, and we can access the list of names by looking at the names attribute of that feature:"
      ],
      "metadata": {
        "id": "_JPgpjYpVJ3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import ClassLabel, Sequence\n",
        "\n",
        "# 1. Get the unique label names from your dataset split (e.g., \"train\")\n",
        "# Replace 'raw_datasets[\"train\"]' and '\"isDif\"' with your actual dataset and column names\n",
        "unique_labels = sorted(set(label for labels in raw_datasets[\"train\"][\"ner_tags\"] for label in labels))\n",
        "# 2. Create a new ClassLabel feature\n",
        "# new_class_label_feature = ClassLabel(names=unique_labels)\n",
        "new_class_label_feature = ClassLabel(num_classes=9, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], names_file=None, id=None)\n",
        "\n",
        "# 3. Cast the column in your dataset to the new ClassLabel feature\n",
        "# This will convert the string labels to their corresponding integer IDs internally\n",
        "raw_datasets = raw_datasets.cast_column(\"ner_tags\", Sequence(feature=new_class_label_feature, length=-1, id=None))\n",
        "\n",
        "# 4. Now you can access the names attribute correctly\n",
        "label_names = raw_datasets[\"train\"].features[\"ner_tags\"].feature.names\n",
        "print(label_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130,
          "referenced_widgets": [
            "cabec90ca4654102a8f6fce4f375f307",
            "3a504834096e41aca2fb43be1461ecbc",
            "93c9976fdca84589825dbf843b354841",
            "8414fe83ece246c199adb8f959bbbe9d",
            "b31eb735c35e445e957fbdbc135b7468",
            "7ffce06ba1a144fd9e53bb79eda7c365",
            "ed148cb421ff4decbb4644e558715c71",
            "d160a607a81a45a4b581fc29e13d2466",
            "2e1a4e42b78c41f9b1bb869656f31d59",
            "eb9c04e307a944658e6577704c7547d9",
            "a56bc83ac2e9447893b025b828e593fd",
            "5ebe7b815bd14f06aeeb633977b3fd05",
            "5c62ff5e714d48169c8b4f2f013a2f87",
            "36ff7d2ce4884e9a8512fde85ce7157d",
            "c61391438ed944fbb47cf3cfa483bdf5",
            "e3b0f78c7ba0483da8c9745c0c3fbd0d",
            "2dc18921c6984cc88d0ca89e8a57e0ad",
            "7426f41981ce45c4b289bc589544571d",
            "76e1372a87cc4551ab1312269790df65",
            "a9fcc573b72042b7b8f5fa6598f734e4",
            "721ec5d85ee242b297b8829cd70fb741",
            "9144b27412c24cc8838f8aad8a79a14c",
            "1698db6fbb2d42d28fe00af3a6468383",
            "5a468c3ec82344e2bba7c632a8a2cd47",
            "1b5eb077777b400b8b8e2ee31b6de8c0",
            "96023aff5a744701b2371e15eb1db06f",
            "fb7ed464eff4414f8a45f3b7417b0ee8",
            "467f40b70cd34a78a8abfe37dc4dd4f9",
            "6b1b8af6fa79437aad74fa9931046cdc",
            "0dff20603eea4d998b73b8bc2fccc15c",
            "ef7c7da388514ce0bb6181db9e89a5f7",
            "a822e9375f554c62ada6e2eda0657fd7",
            "26efa1a1921f4d95acc4e7070fcd9b44"
          ]
        },
        "id": "79zj8TJeOV-W",
        "outputId": "c4953fc8-0673-4d99-9071-72dad0351e1f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Casting the dataset:   0%|          | 0/14041 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cabec90ca4654102a8f6fce4f375f307"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Casting the dataset:   0%|          | 0/3250 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ebe7b815bd14f06aeeb633977b3fd05"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Casting the dataset:   0%|          | 0/3453 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1698db6fbb2d42d28fe00af3a6468383"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we have the numeric representation of the features\n",
        "ner_feature = raw_datasets[\"train\"].features[\"ner_tags\"]\n",
        "ner_feature"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aab6IWkxMIUl",
        "outputId": "25a2dd55-00ff-4baf-f8ef-60d67ad60157"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "List(ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_names = ner_feature.feature.names\n",
        "label_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYtKQxDJQhzK",
        "outputId": "c16f3422-4171-4022-d2fd-b2398b0dae0a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We already saw these labels when digging into the token-classification pipeline in Chapter 6, but for a quick refresher:\n",
        "\n",
        " - O means the word doesnâ€™t correspond to any entity.\n",
        " - B-PER/I-PER means the word corresponds to the beginning of/is inside a person entity.\n",
        " - B-ORG/I-ORG means the word corresponds to the beginning of/is inside an organization entity.\n",
        " - B-LOC/I-LOC means the word corresponds to the beginning of/is inside a location entity.\n",
        " - B-MISC/I-MISC means the word corresponds to the beginning of/is inside a miscellaneous entity.\n",
        "\n",
        "Now decoding the labels we saw earlier gives us this:"
      ],
      "metadata": {
        "id": "JJdyCvrUVWCG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v1Q9FtPRW2e",
        "outputId": "fd66f295-1ddd-4176-ac2a-a4b4ac104d90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EU    rejects German call to boycott British lamb . \n",
            "B-ORG O       B-MISC O    O  O       B-MISC  O    O \n"
          ]
        }
      ],
      "source": [
        "words = raw_datasets[\"train\"][0][\"tokens\"]\n",
        "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
        "line1 = \"\"\n",
        "line2 = \"\"\n",
        "for word, label in zip(words, labels):\n",
        "    full_label = label_names[label]\n",
        "    max_length = max(len(word), len(full_label))\n",
        "    # Format the printout for readability\n",
        "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
        "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
        "\n",
        "print(line1)\n",
        "print(line2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And for an example mixing B- and I- labels, hereâ€™s what the same code gives us on the element of the training set at index 4:"
      ],
      "metadata": {
        "id": "UHavxebxV3hS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "'Germany \\'s representative to the European Union \\'s veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer .'"
      ],
      "metadata": {
        "id": "-6FgNkaRV_Bq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "'B-LOC   O  O              O  O   B-ORG    I-ORG O  O          O         B-PER  I-PER     O    O  O         O         O      O   O         O    O         O     O    B-LOC   O     O   O          O      O   O       O'"
      ],
      "metadata": {
        "id": "MYH8HAK8WOew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, entities spanning two words, like â€œEuropean Unionâ€ and â€œWerner Zwingmann,â€ are attributed a B- label for the first word and an I- label for the second."
      ],
      "metadata": {
        "id": "4yM0wpGVWZO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SR-6vAeVRrn",
        "outputId": "cb6e522f-cfbb-4b2a-a502-6edda0a12e64"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 0, 7, 0, 0, 0, 7, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FchmgPpcWa_K",
        "outputId": "9e310ed6-57b0-4c76-fba9-d25d2404f56a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As usual, our texts need to be converted to token IDs before the model can make sense of them. As in Chapter 6, a big difference in the case of token classification tasks is that we have pre-tokenized inputs. Fortunately, the tokenizer API can deal with that pretty easily; we just need to warn the tokenizer with a special flag.\n",
        "\n",
        "To begin, letâ€™s create our tokenizer object. As we said before, we will be using a BERT pretrained model, so weâ€™ll start by downloading and caching the associated tokenizer:"
      ],
      "metadata": {
        "id": "N8e9l69nWn-E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "161b83d0e4734cf18c8701a097abd507",
            "58eecbab76994fb8ae127acae2777354",
            "7e1a1b96e571432ebbbd891a65c6f026",
            "2011ce9678cd4650b11ce43df813f415",
            "831c4943657d4d33bb9be8f1055fbc52",
            "c38907fa3cca492b9f1e940f3cbec1e8",
            "84d49a4bc0054fc1b422c47e1860a11a",
            "7fb944f7c1c445a08721d8b8f181b79f",
            "5c3b2cfca6c64af191d852e65126d61a",
            "afd891a5d591412884c64d148753c9eb",
            "ebd308c9fb774a628e5f0ea381b4251f",
            "461192d4a9734aaaa9a28618f94c4545",
            "af88d2fe821c4a7d9117fc79219fdadb",
            "dabd7198e7d44d3987bc5d1823b56103",
            "dbfcff1640f6478abf0675cd6bc370f6",
            "6e342b2fd08c4408ac017765c8bfbeba",
            "ab1196193bd649df8a1bd715991e439f",
            "4eb8bd15a62443e7afecd1ed6808bcd8",
            "640a9ebdd4ef4607804cb357fe73e9ea",
            "82ecd7a04d4740b894a92790ab9195e0",
            "7358ee545e574d29b591a4ae917ce0e3",
            "8dcf6fef86a04e5e90cb9f79c49f43db",
            "c9f93e7ed1334d2989426e79191ea387",
            "34d7ad41f6ab447cb02bae54de55f484",
            "0a2b7adbb9f345329a34d8ff3efcf681",
            "8ccb71fbdd7446c5885ed0fb7c161f54",
            "c751334c3ac8493ab4a5216716b80c6e",
            "cdbb91e3026a44df9eaca5a80b44eb55",
            "f7c2abffe0834f98af2ad7db040fc1ee",
            "fda5cef20b93404eb692c9451aa4dcc3",
            "1b61b506ec314bb0a8bac28adf392793",
            "8c3077199b36409bb0809a98d3c53f3c",
            "555d3b99350f45af9e18ddc1fe72d041",
            "05397b62fed44802bbd55c44b5b595d4",
            "d1de145242654aff9822bb54f5ef90d9",
            "564c779889354a7bbf43bd184b5bfa86",
            "6b3d6324056c4aabb36f52835cc938f1",
            "cc285a592ab7474cb6f0c99661c5cf23",
            "7114432aafe74cd18514e5c32178e6ba",
            "8cdb3a00649d4a1f8a16cf2c7b725729",
            "7ec4cd92e0664d408e4b4a01e8e4c3ab",
            "501315fccd0c46c2b3d6e7791a152408",
            "8b50121122114de6bcd8c27cbc50ae80",
            "dcc938dcc9104245abf8e2e6a2925812"
          ]
        },
        "id": "UOkD_XNCRW2f",
        "outputId": "7554281f-b06f-4976-87d0-50450ca4051c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "161b83d0e4734cf18c8701a097abd507"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "461192d4a9734aaaa9a28618f94c4545"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9f93e7ed1334d2989426e79191ea387"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05397b62fed44802bbd55c44b5b595d4"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_checkpoint = \"bert-base-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can replace the model_checkpoint with any other model you prefer from the Hub, or with a local folder in which youâ€™ve saved a pretrained model and a tokenizer. The only constraint is that the tokenizer needs to be backed by the ðŸ¤— Tokenizers library, so thereâ€™s a â€œfastâ€ version available. You can see all the architectures that come with a fast version in this big table, and to check that the tokenizer object youâ€™re using is indeed backed by ðŸ¤— Tokenizers you can look at its is_fast attribute:"
      ],
      "metadata": {
        "id": "ePkZWKB_W6_f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_SH5gT4RW2f",
        "outputId": "d3cdbee9-75e2-489f-a977-403aa9a8734a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "tokenizer.is_fast"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To tokenize a pre-tokenized input, we can use our tokenizer as usual and just add is_split_into_words=True:"
      ],
      "metadata": {
        "id": "HgBuub6KXCGP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7uo4BEMRW2g",
        "outputId": "e65e8abe-c146-4aac-f5d0-4898152bf4a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'EU',\n",
              " 'rejects',\n",
              " 'German',\n",
              " 'call',\n",
              " 'to',\n",
              " 'boycott',\n",
              " 'British',\n",
              " 'la',\n",
              " '##mb',\n",
              " '.',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "inputs = tokenizer(raw_datasets[\"train\"][0][\"tokens\"], is_split_into_words=True)\n",
        "inputs.tokens()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the tokenizer added the special tokens used by the model ([CLS] at the beginning and [SEP] at the end) and left most of the words untouched. The word lamb, however, was tokenized into two subwords, la and ##mb. This introduces a mismatch between our inputs and the labels: the list of labels has only 9 elements, whereas our input now has 12 tokens. Accounting for the special tokens is easy (we know they are at the beginning and the end), but we also need to make sure we align all the labels with the proper words.\n",
        "\n",
        "Fortunately, because weâ€™re using a fast tokenizer we have access to the ðŸ¤— Tokenizers superpowers, which means we can easily map each token to its corresponding word (as seen in Chapter 6):"
      ],
      "metadata": {
        "id": "qvewcHV_XO7G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rw66iiu8RW2g",
        "outputId": "ae0bee2e-ddea-4652-fb69-c24998c923ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "inputs.word_ids()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With a tiny bit of work, we can then expand our label list to match the tokens. The first rule weâ€™ll apply is that special tokens get a label of -100. This is because by default -100 is an index that is ignored in the loss function we will use (cross entropy). Then, each token gets the same label as the token that started the word itâ€™s inside, since they are part of the same entity. For tokens inside a word but not at the beginning, we replace the B- with I- (since the token does not begin the entity):"
      ],
      "metadata": {
        "id": "bZ7INSJxXcYU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Ks1hKd1aRW2h"
      },
      "outputs": [],
      "source": [
        "def align_labels_with_tokens(labels, word_ids):\n",
        "    new_labels = []\n",
        "    current_word = None\n",
        "    for word_id in word_ids:\n",
        "        if word_id != current_word:\n",
        "            # Start of a new word!\n",
        "            current_word = word_id\n",
        "            label = -100 if word_id is None else labels[word_id]\n",
        "            new_labels.append(label)\n",
        "        elif word_id is None:\n",
        "            # Special token\n",
        "            new_labels.append(-100)\n",
        "        else:\n",
        "            # Same word as previous token\n",
        "            label = labels[word_id]\n",
        "            # If the label is B-XXX we change it to I-XXX\n",
        "            if label % 2 == 1:\n",
        "                label += 1\n",
        "            new_labels.append(label)\n",
        "\n",
        "    return new_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Letâ€™s try it out on our first sentence:"
      ],
      "metadata": {
        "id": "VNRGfaR3Xjo7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jK-SKxdvRW2h",
        "outputId": "35275381-453f-41e8-8857-2fc49e0a75ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 0, 7, 0, 0, 0, 7, 0, 0]\n",
            "[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]\n"
          ]
        }
      ],
      "source": [
        "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
        "word_ids = inputs.word_ids()\n",
        "print(labels)\n",
        "print(align_labels_with_tokens(labels, word_ids))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, our function added the -100 for the two special tokens at the beginning and the end, and a new 0 for our word that was split into two tokens."
      ],
      "metadata": {
        "id": "yBtkB8-WXt80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E18-mkYuQruH",
        "outputId": "f54c880c-97aa-4780-ba57-9c7b1e32c733"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To preprocess our whole dataset, we need to tokenize all the inputs and apply align_labels_with_tokens() on all the labels. To take advantage of the speed of our fast tokenizer, itâ€™s best to tokenize lots of texts at the same time, so weâ€™ll write a function that processes a list of examples and use the Dataset.map() method with the option batched=True. The only thing that is different from our previous example is that the word_ids() function needs to get the index of the example we want the word IDs of when the inputs to the tokenizer are lists of texts (or in our case, list of lists of words), so we add that too:"
      ],
      "metadata": {
        "id": "ZbhNSKAsX2bN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "zWnxF-tURW2i"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
        "    )\n",
        "    all_labels = examples[\"ner_tags\"]\n",
        "    new_labels = []\n",
        "    for i, labels in enumerate(all_labels):\n",
        "        word_ids = tokenized_inputs.word_ids(i)\n",
        "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = new_labels\n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that we havenâ€™t padded our inputs yet; weâ€™ll do that later, when creating the batches with a data collator.\n",
        "\n",
        "We can now apply all that preprocessing in one go on the other splits of our dataset:"
      ],
      "metadata": {
        "id": "oC3cIY8xX-5B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "2f41e48787af410d91562d3cb769924a",
            "db79ac948aa34d32863d1369b0b985bb",
            "0b76fc9fc5db46fe86873e11d091738f",
            "eb83361694e6422484bd99b56ecbd2fc",
            "a382332557b245ecb441fd0f7400b2b8",
            "1b6457cf00874ffe8ffaf48fd3e02262",
            "26ee7cadfa99438cb9e94226e280ee9d",
            "2ba20823e8df49fbacfa7c773ae44876",
            "7486b66d0874440bb3a35ff3fd998290",
            "2297e4f1da834da6bf4a760be472f3a0",
            "8316779938d642fda024065050f2d197",
            "8a03f21ceb8a4994b34cf17e70412a4d",
            "d27323f9101a41be8483b200bcfb4a9e",
            "b750e39d93fd47e58704f8502a4b8f52",
            "223c6539bf3a49af83bbfde6658d8763",
            "d40127b2fa5b4e93925bc23eacb8c92f",
            "ccf9545d2cf74fdfbf8364770d6660c6",
            "8b2eefe1ef544db4bd4dd97e88e7ab62",
            "0bd6d11fc7f6477e9cd7676813bc12ae",
            "8a895f2129bc48a4abe5d70079c3301c",
            "a1c41f90d0cb4379857e8ddbf64cf663",
            "5f4de2ed9acc48f5aaac49dd67d66670",
            "403215ca9ad64615a1e5306be64440e1",
            "6a4568bee4c24641a2c6cc1b78c7785b",
            "34fb1be797c54edebecc756e995359a7",
            "0496d6d10e9c46fa90ba7c2f230168b2",
            "f936bdac72e84ee18682b8cbdf788aa8",
            "a1c3e87177164098807df79599a09e51",
            "77c69d9d640c4ec1888045b57a7e29d5",
            "479f28813ef54548b9df9afa8966da70",
            "dfc312f968cb405ebb0b34019a79e1db",
            "70d28debfe7046bdaa50654b9ca2fc3c",
            "5759fa9f055846909d959c3ffb4f8650"
          ]
        },
        "id": "BbK_IV6SRW2i",
        "outputId": "2e988db7-1736-4fe8-b84f-c65f41bc5cc9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/14041 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f41e48787af410d91562d3cb769924a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3250 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a03f21ceb8a4994b34cf17e70412a4d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3453 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "403215ca9ad64615a1e5306be64440e1"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenized_datasets = raw_datasets.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    remove_columns=raw_datasets[\"train\"].column_names,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Weâ€™ve done the hardest part! Now that the data has been preprocessed, the actual training will look a lot like what we did in Chapter 3."
      ],
      "metadata": {
        "id": "58rizKlHYPIM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning the model with the Trainer API"
      ],
      "metadata": {
        "id": "wRYcLLyUYT27"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The actual code using the Trainer will be the same as before; the only changes are the way the data is collated into a batch and the metric computation function."
      ],
      "metadata": {
        "id": "Zlt7375sYYAa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data collation"
      ],
      "metadata": {
        "id": "URSr20gtYlml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We canâ€™t just use a DataCollatorWithPadding like in Chapter 3 because that only pads the inputs (input IDs, attention mask, and token type IDs). Here our labels should be padded the exact same way as the inputs so that they stay the same size, using -100 as a value so that the corresponding predictions are ignored in the loss computation.\n",
        "\n",
        "This is all done by a DataCollatorForTokenClassification. Like the DataCollatorWithPadding, it takes the tokenizer used to preprocess the inputs:"
      ],
      "metadata": {
        "id": "zwboX_GFYh0I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "jt9axCvWRW2j"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To test this on a few samples, we can just call it on a list of examples from our tokenized training set:"
      ],
      "metadata": {
        "id": "1VUBd_y8ZD-I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-t1V_6dfRW2j",
        "outputId": "1fd2f08a-5456-4d7e-c9e7-46188c98a188"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-100,    3,    0,    7,    0,    0,    0,    7,    0,    0,    0, -100],\n",
              "        [-100,    1,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])\n",
        "batch[\"labels\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Letâ€™s compare this to the labels for the first and second elements in our dataset:"
      ],
      "metadata": {
        "id": "m91yuj1_ZJff"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZZtOVG1RW2k",
        "outputId": "8739d5b3-63ab-4e60-bce6-e50de9dd594f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]\n",
            "[-100, 1, 2, -100]\n"
          ]
        }
      ],
      "source": [
        "for i in range(2):\n",
        "    print(tokenized_datasets[\"train\"][i][\"labels\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the second set of labels has been padded to the length of the first one using -100s."
      ],
      "metadata": {
        "id": "saDDo2DuZtIS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UVhvVDToZ6E0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metrics"
      ],
      "metadata": {
        "id": "7PAPS5A7Z1Ji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To have the Trainer compute a metric every epoch, we will need to define a compute_metrics() function that takes the arrays of predictions and labels, and returns a dictionary with the metric names and values.\n",
        "\n",
        "The traditional framework used to evaluate token classification prediction is seqeval. To use this metric, we first need to install the seqeval library:"
      ],
      "metadata": {
        "id": "mnPfARhRZxOt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV-A6pCeRW2k",
        "outputId": "598e4fb6-9ec6-433f-9801-25fe5267aed6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from seqeval) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.12/dist-packages (from seqeval) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=42b05ef8e0e7822f326f242baea20358f25796cbebc2d43be2b965dc9ceb1f7e\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/b8/73/0b2c1a76b701a677653dd79ece07cfabd7457989dbfbdcd8d7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.6\n"
          ]
        }
      ],
      "source": [
        "!pip install seqeval\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then load it via the evaluate.load() function"
      ],
      "metadata": {
        "id": "_zLyq5V9aB9N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "fef99635b7164f42a2b1c13e2ef70f3a",
            "213a139ddc774006b74c0366773043d5",
            "643674e6ef414b83955c246969b4cee8",
            "3ba670e8ffc84a3abe72b625f3ff5efc",
            "edbd31a5d4fd402fb468f9c5bfb72ab9",
            "0dbcf7ae6ce24f899898a9065ea44d88",
            "fb84a233e44642cda89ca28684501838",
            "c9f0def016134b408544995f8916fefd",
            "fde256d1df514f2a9058981926689a2c",
            "4924dd6a396246a98d67bf80534355ec",
            "aeff566478e947198795c37e6b83b170"
          ]
        },
        "id": "IgIr-g2ORW2l",
        "outputId": "cb862f31-e244-4e44-ae22-21bf087ec6bc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fef99635b7164f42a2b1c13e2ef70f3a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"seqeval\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This metric does not behave like the standard accuracy: it will actually take the lists of labels as strings, not integers, so we will need to fully decode the predictions and labels before passing them to the metric. Letâ€™s see how it works. First, weâ€™ll get the labels for our first training example:"
      ],
      "metadata": {
        "id": "KjyOc5u5aRU9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpoZ5jaHRW2m",
        "outputId": "36902d1c-7c37-4446-f2a9-a2a53d24e175"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
        "labels = [label_names[i] for i in labels]\n",
        "labels"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then create fake predictions for those by just changing the value at index 2:"
      ],
      "metadata": {
        "id": "Bo4FCU4ImX8J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyiedxyjRW2m",
        "outputId": "d0366dce-2f1c-45c8-ddad-e264b7df1152"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MISC': {'precision': np.float64(1.0),\n",
              "  'recall': np.float64(0.5),\n",
              "  'f1': np.float64(0.6666666666666666),\n",
              "  'number': np.int64(2)},\n",
              " 'ORG': {'precision': np.float64(1.0),\n",
              "  'recall': np.float64(1.0),\n",
              "  'f1': np.float64(1.0),\n",
              "  'number': np.int64(1)},\n",
              " 'overall_precision': np.float64(1.0),\n",
              " 'overall_recall': np.float64(0.6666666666666666),\n",
              " 'overall_f1': np.float64(0.8),\n",
              " 'overall_accuracy': 0.8888888888888888}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "predictions = labels.copy()\n",
        "predictions[2] = \"O\"\n",
        "metric.compute(predictions=[predictions], references=[labels])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is sending back a lot of information! We get the precision, recall, and F1 score for each separate entity, as well as overall. For our metric computation we will only keep the overall score, but feel free to tweak the compute_metrics() function to return all the metrics you would like reported.\n",
        "\n",
        "This compute_metrics() function first takes the argmax of the logits to convert them to predictions (as usual, the logits and the probabilities are in the same order, so we donâ€™t need to apply the softmax). Then we have to convert both labels and predictions from integers to strings. We remove all the values where the label is -100, then pass the results to the metric.compute() method:"
      ],
      "metadata": {
        "id": "YuG5ZJLjax_C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "5kUzt5SbRW2m"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Remove ignored index (special tokens) and convert to labels\n",
        "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
        "    true_predictions = [\n",
        "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": all_metrics[\"overall_precision\"],\n",
        "        \"recall\": all_metrics[\"overall_recall\"],\n",
        "        \"f1\": all_metrics[\"overall_f1\"],\n",
        "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that this is done, we are almost ready to define our Trainer. We just need a model to fine-tune!"
      ],
      "metadata": {
        "id": "TKRg7nXfik9v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining the model"
      ],
      "metadata": {
        "id": "mEEOOC2YisqT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we are working on a token classification problem, we will use the AutoModelForTokenClassification class. The main thing to remember when defining this model is to pass along some information on the number of labels we have. The easiest way to do this is to pass that number with the num_labels argument, but if we want a nice inference widget working like the one we saw at the beginning of this section, itâ€™s better to set the correct label correspondences instead.\n",
        "\n",
        "They should be set by two dictionaries, id2label and label2id, which contain the mappings from ID to label and vice versa:"
      ],
      "metadata": {
        "id": "RDh26Inzip3R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "6U9UF19sRW2n"
      },
      "outputs": [],
      "source": [
        "id2label = {i: label for i, label in enumerate(label_names)}\n",
        "label2id = {v: k for k, v in id2label.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can just pass them to the AutoModelForTokenClassification.from_pretrained() method, and they will be set in the modelâ€™s configuration and then properly saved and uploaded to the Hub:"
      ],
      "metadata": {
        "id": "yI1LHdvpi1E5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "0a1ce48dbbc6430586c145c2db049417",
            "db830d33604c4ae1b35f6fdb1fff2598",
            "ed9c94c6f711405882f38b75b7664a31",
            "c4f641e2f9af4ed98784d8729aa19bad",
            "bc34a7dc5a894ad98e2df80e33a65f09",
            "70b7ac1d59924d8da2c4ed87d349f554",
            "64793ecfd484446b815d3d37c8316ff5",
            "b61bbaba40f04c0dbe88d3bb79ff19f6",
            "20b4f7971efb473f8b250ae47da8a2f2",
            "f7fd616999464a048e44caab5066201d",
            "409c19b4dbfb4916a06eab7ea6c88ad6"
          ]
        },
        "id": "0TD2KKl_RW2n",
        "outputId": "3f9b8402-d6f1-4e2a-fcfd-b66ed44eb95c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a1ce48dbbc6430586c145c2db049417"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Like when we defined our AutoModelForSequenceClassification in Chapter 3, creating the model issues a warning that some weights were not used (the ones from the pretraining head) and some other weights are randomly initialized (the ones from the new token classification head), and that this model should be trained. We will do that in a minute, but first letâ€™s double-check that our model has the right number of labels:"
      ],
      "metadata": {
        "id": "MubIA2dHD2NO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9l72h0eORW2p",
        "outputId": "90ccb4b9-d446-45b2-b7b3-398732e3ca5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "model.config.num_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-tuning the model"
      ],
      "metadata": {
        "id": "ZencMypGjF5A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are now ready to train our model! We just need to do two last things before we define our Trainer: log in to Hugging Face and define our training arguments. If youâ€™re working in a notebook, thereâ€™s a convenience function to help you with this:"
      ],
      "metadata": {
        "id": "Go8lFJPfjDIa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "9765797d7c4d4f1cac3bd545eaff44e4",
            "f281b0bbc49a4c5a879eeddcfa83baa8",
            "5eaf996d2f6b4d00a8e03732244b308b",
            "b8d0501ee68c4accb1f042c8d2475f61",
            "1bbb8cf816d04a46a24233b3e4f08120",
            "4e4b0e0fc0af475a9fdfdcb8fabec358",
            "ed5830aeccd349a185b1196d5b04b0e2",
            "93b20fc3947347069a370d2b816f71b2",
            "3b0a899eac9a4622887ce9dfe287976f",
            "94896ae506cb430bbc5dd55cec934e6a",
            "45a4a742684b4a85b0f2d04d00a4eb4e",
            "03e7d396c83346b499135075a9a503a1",
            "9134f0a24d9c4f2a8520ec563b9d9478",
            "acda0169e3ec4c22a9cc10fb27081ede",
            "3fb362135d2343759edc2536ab9e1561",
            "9995f81747ae4736907be4a13acec7b6",
            "7c88b6be845c468788b285efa2ddce3d",
            "36194884390c4e91921d49ef804dd922",
            "b20859e310f64e68b62cac749282748a",
            "83e3324ab6064009aec7449000d19b01"
          ]
        },
        "id": "ptHg_uvBRW2q",
        "outputId": "09558be0-67b0-4515-a599-288b59570f46"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9765797d7c4d4f1cac3bd545eaff44e4"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will display a widget where you can enter your Hugging Face login credentials.\n",
        "\n",
        "If you arenâ€™t working in a notebook, just type the following line in your terminal:\n",
        "\n",
        ":> huggingface-cli login"
      ],
      "metadata": {
        "id": "lmjdD5wnjUcq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once this is done, we can define our TrainingArguments:"
      ],
      "metadata": {
        "id": "Wy_M0PvMjkbb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "beo22MLKRW2q"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "    \"bert-finetuned-ner\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    push_to_hub=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Youâ€™ve seen most of those before: we set some hyperparameters (like the learning rate, the number of epochs to train for, and the weight decay), and we specify push_to_hub=True to indicate that we want to save the model and evaluate it at the end of every epoch, and that we want to upload our results to the Model Hub. Note that you can specify the name of the repository you want to push to with the hub_model_id argument (in particular, you will have to use this argument to push to an organization). For instance, when we pushed the model to the huggingface-course organization, we added hub_model_id=\"huggingface-course/bert-finetuned-ner\" to TrainingArguments. By default, the repository used will be in your namespace and named after the output directory you set, so in our case it will be \"sgugger/bert-finetuned-ner\"."
      ],
      "metadata": {
        "id": "xWdvCp1YjveT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we just pass everything to the Trainer and launch the training:"
      ],
      "metadata": {
        "id": "B2bUJ-CPj1ZV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "3Z5db_vRRW2r",
        "outputId": "f5e91149-d917-4b04-e369-84e065c6335c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3203677919.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjosteece\u001b[0m (\u001b[33mjosteece-process-dynamics-and-automation-systems\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251118_182234-cy5gt07h</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/josteece-process-dynamics-and-automation-systems/huggingface/runs/cy5gt07h' target=\"_blank\">vibrant-water-2</a></strong> to <a href='https://wandb.ai/josteece-process-dynamics-and-automation-systems/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/josteece-process-dynamics-and-automation-systems/huggingface' target=\"_blank\">https://wandb.ai/josteece-process-dynamics-and-automation-systems/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/josteece-process-dynamics-and-automation-systems/huggingface/runs/cy5gt07h' target=\"_blank\">https://wandb.ai/josteece-process-dynamics-and-automation-systems/huggingface/runs/cy5gt07h</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5268' max='5268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5268/5268 09:40, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.077300</td>\n",
              "      <td>0.072613</td>\n",
              "      <td>0.900998</td>\n",
              "      <td>0.926624</td>\n",
              "      <td>0.913631</td>\n",
              "      <td>0.979161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.033800</td>\n",
              "      <td>0.069320</td>\n",
              "      <td>0.926930</td>\n",
              "      <td>0.943622</td>\n",
              "      <td>0.935201</td>\n",
              "      <td>0.984444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.022300</td>\n",
              "      <td>0.062699</td>\n",
              "      <td>0.932044</td>\n",
              "      <td>0.948670</td>\n",
              "      <td>0.940284</td>\n",
              "      <td>0.985930</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5268, training_loss=0.06640659052038518, metrics={'train_runtime': 598.9353, 'train_samples_per_second': 70.33, 'train_steps_per_second': 8.796, 'total_flos': 920771584279074.0, 'train_loss': 0.06640659052038518, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that while the training happens, each time the model is saved (here, every epoch) it is uploaded to the Hub in the background. This way, you will be able to to resume your training on another machine if necessary.\n",
        "\n",
        "Once the training is complete, we use the push_to_hub() method to make sure we upload the most recent version of the model:"
      ],
      "metadata": {
        "id": "H0bI9Dnfj9mO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246,
          "referenced_widgets": [
            "551eb8a83f9e4b269f1195d27594d850",
            "67994b4c34114a61913478b6f1fe064f",
            "2e9bdfb7e11a44fca70da5fbf4083da0",
            "81801bcf2af24fadb55ac64d05ee8240",
            "73949af5eca4403a895b321798b72cc5",
            "97fcb9c746e14f31a3d87c72ddc2642d",
            "383c66997fc044ec9c2b8bcf33bdc8bf",
            "7b6e7461b1fc4837b8fe11c21528f084",
            "107f69ba4f964a35b2f7a628b43d5bf1",
            "917bd36ffdb14be8a7addce6a7e36120",
            "b730163935ce4f76a6ac40fde7baea95",
            "0615c369c2744745ba6dff0fdb36c06a",
            "677abf1e336944148edb5ac2c4498c12",
            "713b11f48bb54a139003881476dc89dd",
            "239e6b551f164b328e61aa02d6133471",
            "c97927cb62834d93a2aa4d64dab6015a",
            "ae0fa3d03da54468b7086e854454f8e6",
            "1cb83f2137e94a3594398b1815133fe0",
            "ce0d7b7c23264d1bb08fb6fe93b57034",
            "850684e726494308ae6c004a375b17a3",
            "8151da28c9a741a8bb0bc161a71021e6",
            "d233d96ad5944d5abfb70fb5c88afb68",
            "26087dc46fda4cb08d40d3f0b3daea51",
            "7b0437a4abe64cb090954b35e3feab74",
            "42137e9948c149c799a48e987b04d1a7",
            "fe385778c54c40cba1a1c1681f8ca513",
            "bcdda51a8ad444f6b8014d6071a58a23",
            "c8f3dd98ad2540f6bebd212f56b95a2a",
            "c3af8e073f4949558172453a292df04b",
            "a1cba4e3d94c435e9f88cdc5e0b83afd",
            "ed03d581094749d69c5afd45696d8b5c",
            "ef072d792d394ea0b420353a5a9f469d",
            "a10d5fa7a3af4a23b7730d5517be956f",
            "b319ff22f57f40f7b0c53909cfc3019a",
            "225b9ef7bd284ec29bb7e75906b061b1",
            "fad7257adf994300b9728020c805781c",
            "2e37f18f5497408b968f2ea339136036",
            "98f0bbffbc7e4ed99ddfc060a48f1297",
            "327f7de883be4c6c87e62fd2ceb173be",
            "8a8404a7c139400cabee852eb8ddfc01",
            "a216ae372bea41d88fe6bcc6cbb69ee2",
            "c587cf298a1b401888b26c7b9710484f",
            "df54a5abbcc7417394804a2bfe569805",
            "59441f2086ca4701a2842695c00f6ea6",
            "9e268998b0c94e16aa4d7d50e60ba2de",
            "dcd885848c3e42fe8464cc1d1a2a7b27",
            "ed72cc659a64491b90ee15d504987599",
            "31632c23423745a4bc62c8b4b6428782",
            "26174576d8904f2aa3f9e7fa4b5034bb",
            "68383c4f6a7f48f48fca95e2e8e4a57b",
            "df1c1bed44ab4ee98f715e224b443207",
            "081022bbdccc496bb9e77c692cdd0e21",
            "e6cfaf7fb8d0479897dfab9dfb5ccda7",
            "a6576d2cade74d20a3c992ffa1c3f8c0",
            "da536dddcb30458db1aa710cce5bc1c1"
          ]
        },
        "id": "yjaGdsW_RW2r",
        "outputId": "c2cb6e89-a0e1-44dc-da13-5b075bbe5e56"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "551eb8a83f9e4b269f1195d27594d850"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "New Data Upload               : |          |  0.00B /  0.00B            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0615c369c2744745ba6dff0fdb36c06a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...ned-ner/training_args.bin: 100%|##########| 5.84kB / 5.84kB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26087dc46fda4cb08d40d3f0b3daea51"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...490141.580eee1635f2.171.0: 100%|##########| 9.24kB / 9.24kB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b319ff22f57f40f7b0c53909cfc3019a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...ned-ner/model.safetensors:   8%|7         | 33.5MB /  431MB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e268998b0c94e16aa4d7d50e60ba2de"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/josteece/bert-finetuned-ner/commit/2e63c56fb394b0fb3e079bce281faeb7d67d2bd1', commit_message='Training complete', commit_description='', oid='2e63c56fb394b0fb3e079bce281faeb7d67d2bd1', pr_url=None, repo_url=RepoUrl('https://huggingface.co/josteece/bert-finetuned-ner', endpoint='https://huggingface.co', repo_type='model', repo_id='josteece/bert-finetuned-ner'), pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "trainer.push_to_hub(commit_message=\"Training complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Trainer also drafts a model card with all the evaluation results and uploads it. At this stage, you can use the inference widget on the Model Hub to test your model and share it with your friends. You have successfully fine-tuned a model on a token classification task â€” congratulations!\n",
        "\n",
        "If you want to dive a bit more deeply into the training loop, we will now show you how to do the same thing using ðŸ¤— Accelerate."
      ],
      "metadata": {
        "id": "QgKq3EwjkS4Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A custom training loop"
      ],
      "metadata": {
        "id": "AsTC2-PTkdTn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Letâ€™s now take a look at the full training loop, so you can easily customize the parts you need. It will look a lot like what we did in Chapter 3, with a few changes for the evaluation."
      ],
      "metadata": {
        "id": "qsAv093-kaeW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing everything for training\n",
        "First we need to build the DataLoaders from our datasets. Weâ€™ll reuse our data_collator as a collate_fn and shuffle the training set, but not the validation set:"
      ],
      "metadata": {
        "id": "27m4AJTVkq57"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "OeR8elddRW2r"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"train\"],\n",
        "    shuffle=True,\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=8,\n",
        ")\n",
        "eval_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"validation\"], collate_fn=data_collator, batch_size=8\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we reinstantiate our model, to make sure weâ€™re not continuing the fine-tuning from before but starting from the BERT pretrained model again:"
      ],
      "metadata": {
        "id": "kIx6IFzokoxN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eYRFSfmRW2s",
        "outputId": "9acd5286-5a21-4ad1-88e8-7b39a187c175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we will need an optimizer. Weâ€™ll use the classic AdamW, which is like Adam, but with a fix in the way weight decay is applied:"
      ],
      "metadata": {
        "id": "EFwSfWamlA4U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "-3wctj6qRW2t"
      },
      "outputs": [],
      "source": [
        "from torch.optim import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we have all those objects, we can send them to the accelerator.prepare() method:"
      ],
      "metadata": {
        "id": "OiAGb2PblmeG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "vSCDvxjsRW2t"
      },
      "outputs": [],
      "source": [
        "from accelerate import Accelerator\n",
        "\n",
        "accelerator = Accelerator()\n",
        "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
        "    model, optimizer, train_dataloader, eval_dataloader\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸš¨ If youâ€™re training on a TPU, youâ€™ll need to move all the code starting from the cell above into a dedicated training function."
      ],
      "metadata": {
        "id": "RMSRHi-Hl4Xz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have sent our train_dataloader to accelerator.prepare(), we can use its length to compute the number of training steps. Remember that we should always do this after preparing the dataloader, as that method will change its length. We use a classic linear schedule from the learning rate to 0:"
      ],
      "metadata": {
        "id": "aJnT0Wg-l3BX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "uVU83U4rRW2u"
      },
      "outputs": [],
      "source": [
        "from transformers import get_scheduler\n",
        "\n",
        "num_train_epochs = 3\n",
        "num_update_steps_per_epoch = len(train_dataloader)\n",
        "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
        "\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, to push our model to the Hub, we will need to create a Repository object in a working folder. First log in to Hugging Face, if youâ€™re not logged in already. Weâ€™ll determine the repository name from the model ID we want to give our model (feel free to replace the repo_name with your own choice; it just needs to contain your username, which is what the function get_full_repo_name() does):"
      ],
      "metadata": {
        "id": "SWz0LmKqmIZj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You need to logon to Huggingface hub first."
      ],
      "metadata": {
        "id": "DAeSJpPmmfDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "557a2492a8244d208ad7c71937722230",
            "feb1930649474e1bb3c88b2647d4c917",
            "01d8da225bb54243ad8ad736f3c46776",
            "5aefb54405834049a051e84e74ee2a3a",
            "0ff93de30b28485bbf554c83621efb17",
            "d7193eec7b104e16a5e8992f711f7952",
            "f73878bb5fc84776912d5de535518fa1",
            "568512ff22784bdcad27ae19050e7374",
            "da9acceb1dee4047ad36e671ecd11ec1",
            "f7e65807dec64fe289c605cf22fc42c5",
            "2b4999cec5c1417aa55431a05a005a41",
            "a6050a93c40f47a29f170bef88b3a2e1",
            "5ea1c7eff30042cda793b1ba221471bd",
            "80426d7c290248f7afb59f7eb482afcb",
            "607ddcb250fb4b6bb50a872ec6dcaa3d",
            "96c9043f5fbd47f0908b161f1593964a",
            "2fcae2c7eabd48598c8ae2a77b8df889",
            "1c75c8ccc1a24001a2c9c36bb73aaf03",
            "660fee1dbe01472d881d8cf0bfa379b1",
            "f038e555208a4440af0944030d92d0ae"
          ]
        },
        "id": "XA4sUgeMnlVT",
        "outputId": "f08b0b45-4c9f-4b2a-e7cc-0376dbe149a6"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "557a2492a8244d208ad7c71937722230"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import create_repo\n",
        "\n",
        "# The repo_id must be in the format \"username_or_org/repo_name\"\n",
        "repo_id = \"josteece/bert-finetuned-ner-accelerate\"\n",
        "\n",
        "# Create a public model repository (default type)\n",
        "create_repo(repo_id=repo_id)\n",
        "print(f\"Repository created at:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "kojQfrtNm_Da",
        "outputId": "55c6bafe-f2f9-4218-c4ec-3abf370b69d1"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "HfHubHTTPError",
          "evalue": "409 Client Error: Conflict for url: https://huggingface.co/api/repos/create (Request ID: Root=1-691d5bdd-64b2171a7bb1699d6e68e051;e6a4d914-7f8e-4a84-b6ed-c5e18892a3bd)\n\nYou already created this model repo: josteece/bert-finetuned-ner-accelerate",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 409 Client Error: Conflict for url: https://huggingface.co/api/repos/create",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-276904932.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Create a public model repository (default type)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcreate_repo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Repository created at:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36mcreate_repo\u001b[0;34m(self, repo_id, token, private, repo_type, exist_ok, resource_group_id, space_sdk, space_hardware, space_storage, space_sleep_time, space_secrets, space_variables)\u001b[0m\n\u001b[1;32m   3758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3759\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3760\u001b[0;31m             \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3761\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3762\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mexist_ok\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m409\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;31m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;31m# as well (request id and/or server error message)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHfHubHTTPError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHfHubHTTPError\u001b[0m: 409 Client Error: Conflict for url: https://huggingface.co/api/repos/create (Request ID: Root=1-691d5bdd-64b2171a7bb1699d6e68e051;e6a4d914-7f8e-4a84-b6ed-c5e18892a3bd)\n\nYou already created this model repo: josteece/bert-finetuned-ner-accelerate"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we can clone that repository in a local folder. If it already exists, this local folder should be an existing clone of the repository we are working with:"
      ],
      "metadata": {
        "id": "QwlTYLqOmbMA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VFQGds-LRW2u",
        "outputId": "93da265f-107d-41de-b71d-853ccd4b0615"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'josteece/bert-finetuned-ner-accelerate'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "from huggingface_hub import Repository, get_full_repo_name\n",
        "\n",
        "model_name = \"bert-finetuned-ner-accelerate\"\n",
        "repo_name = get_full_repo_name(model_name)\n",
        "repo_name"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now upload anything we save in output_dir by calling the repo.push_to_hub() method. This will help us upload the intermediate models at the end of each epoch."
      ],
      "metadata": {
        "id": "2XxbrE5Qmux_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6LecCRYRW2v",
        "outputId": "5db14629-cc38-41a4-fb75-94d565c26340"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
            "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "Cloning https://huggingface.co/josteece/bert-finetuned-ner-accelerate into local empty directory.\n",
            "WARNING:huggingface_hub.repository:Cloning https://huggingface.co/josteece/bert-finetuned-ner-accelerate into local empty directory.\n"
          ]
        }
      ],
      "source": [
        "output_dir = \"bert-finetuned-ner-accelerate\"\n",
        "repo = Repository(output_dir, clone_from=repo_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training loop"
      ],
      "metadata": {
        "id": "EmeZANKSm4IF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are now ready to write the full training loop. To simplify its evaluation part, we define this postprocess() function that takes predictions and labels and converts them to lists of strings, like our metric object expects:"
      ],
      "metadata": {
        "id": "O4cBdWtmm1Hn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "g6F4fPILRW2v"
      },
      "outputs": [],
      "source": [
        "def postprocess(predictions, labels):\n",
        "    predictions = predictions.detach().cpu().clone().numpy()\n",
        "    labels = labels.detach().cpu().clone().numpy()\n",
        "\n",
        "    # Remove ignored index (special tokens) and convert to labels\n",
        "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
        "    true_predictions = [\n",
        "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    return true_labels, true_predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we can write the training loop. After defining a progress bar to follow how training goes, the loop has three parts:\n",
        "\n",
        " - The training in itself, which is the classic iteration over the train_dataloader, forward pass through the model, then backward pass and optimizer step.\n",
        " - The evaluation, in which there is a novelty after getting the outputs of our model on a batch: since two processes may have padded the inputs and labels to different shapes, we need to use accelerator.pad_across_processes() to make the predictions and labels the same shape before calling the gather() method. If we donâ€™t do this, the evaluation will either error out or hang forever. Then we send the results to metric.add_batch() and call metric.compute() once the evaluation loop is over.\n",
        " - Saving and uploading, where we first save the model and the tokenizer, then call repo.push_to_hub(). Notice that we use the argument blocking=False to tell the ðŸ¤— Hub library to push in an asynchronous process. This way, training continues normally and this (long) instruction is executed in the background.\n",
        "\n",
        "Hereâ€™s the complete code for the training loop:"
      ],
      "metadata": {
        "id": "S3NRTTy_nCVI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute the following commands in your terminal or in the relevant notebook cell before the code that attempts the Git commit:"
      ],
      "metadata": {
        "id": "Fj-okmAJy5UE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"josteece@googlemail.com\"\n",
        "!git config --global user.name \"Josteece\"\n"
      ],
      "metadata": {
        "id": "5fjd1ZW3thOq"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "4c6f19b4f5794bfa87d6848913b3b521",
            "f6d7488e53c041e9ad969df82a3256a8",
            "80b0cd5741684d558fe0386b11c56b63",
            "54c61ecbd5fb40249d0b3b6a7e855b89",
            "17d0ccbfc2dc446b86d9c967f8cdf623",
            "7c9f4f2a576240a2b75e9ac6e82a11c2",
            "4d47b95411e447beb4a5a68053332ff5",
            "db43c833e3eb4df38a3d99278bfa2914",
            "453d449e0d6e4d1f9ce55aa342afa0c5",
            "961505cc74be4e1b93e9d562e1d3ec31",
            "e0431606e5b9421eb092ef4e117cd5ac"
          ]
        },
        "id": "qVZftMYfRW2w",
        "outputId": "0c778ded-9643-40e6-b7aa-440aa9a43e87"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5268 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c6f19b4f5794bfa87d6848913b3b521"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0: {'precision': np.float64(0.935880175025244), 'recall': np.float64(0.911340544083907), 'f1': np.float64(0.9234473596811691), 'accuracy': 0.9823100017660564}\n",
            "epoch 1: {'precision': np.float64(0.9461460787613598), 'recall': np.float64(0.9248231617042276), 'f1': np.float64(0.9353631145495382), 'accuracy': 0.9856507917819509}\n",
            "epoch 2: {'precision': np.float64(0.9461460787613598), 'recall': np.float64(0.9248231617042276), 'f1': np.float64(0.9353631145495382), 'accuracy': 0.9856507917819509}\n"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "for epoch in range(num_train_epochs):\n",
        "    # Training\n",
        "    model.train()\n",
        "    for batch in train_dataloader:\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        accelerator.backward(loss)\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    for batch in eval_dataloader:\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "\n",
        "        predictions = outputs.logits.argmax(dim=-1)\n",
        "        labels = batch[\"labels\"]\n",
        "\n",
        "        # Necessary to pad predictions and labels for being gathered\n",
        "        predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n",
        "        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
        "\n",
        "        predictions_gathered = accelerator.gather(predictions)\n",
        "        labels_gathered = accelerator.gather(labels)\n",
        "\n",
        "        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n",
        "        metric.add_batch(predictions=true_predictions, references=true_labels)\n",
        "\n",
        "    results = metric.compute()\n",
        "    print(\n",
        "        f\"epoch {epoch}:\",\n",
        "        {\n",
        "            key: results[f\"overall_{key}\"]\n",
        "            for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]\n",
        "        },\n",
        "    )\n",
        "\n",
        "    # Save and upload\n",
        "    accelerator.wait_for_everyone()\n",
        "    unwrapped_model = accelerator.unwrap_model(model)\n",
        "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
        "    if accelerator.is_main_process:\n",
        "        tokenizer.save_pretrained(output_dir)\n",
        "        repo.push_to_hub(\n",
        "            commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In case this is the first time youâ€™re seeing a model saved with ðŸ¤— Accelerate, letâ€™s take a moment to inspect the three lines of code that go with it:"
      ],
      "metadata": {
        "id": "8pAGCMNGnR8J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "Rd6r0MmCRW2x"
      },
      "outputs": [],
      "source": [
        "accelerator.wait_for_everyone()\n",
        "unwrapped_model = accelerator.unwrap_model(model)\n",
        "unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first line is self-explanatory: it tells all the processes to wait until everyone is at that stage before continuing. This is to make sure we have the same model in every process before saving. Then we grab the unwrapped_model, which is the base model we defined. The accelerator.prepare() method changes the model to work in distributed training, so it wonâ€™t have the save_pretrained() method anymore; the accelerator.unwrap_model() method undoes that step. Lastly, we call save_pretrained() but tell that method to use accelerator.save() instead of torch.save().\n",
        "\n",
        "Once this is done, you should have a model that produces results pretty similar to the one trained with the Trainer. You can check the model we trained using this code at huggingface-course/bert-finetuned-ner-accelerate. And if you want to test out any tweaks to the training loop, you can directly implement them by editing the code shown above!"
      ],
      "metadata": {
        "id": "tjN2dFspnf42"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using the fine-tuned model\n",
        "Weâ€™ve already shown you how you can use the model we fine-tuned on the Model Hub with the inference widget. To use it locally in a pipeline, you just have to specify the proper model identifier:"
      ],
      "metadata": {
        "id": "tZQ36VPRnrzp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487,
          "referenced_widgets": [
            "f00af10cb8ec4c648bc5f76aee508a06",
            "09828fcc1b6b44c38c03e2325c3ecc5d",
            "dbdef4cec546496b9b653c3b245e4f5c",
            "9e5f9bcdc2474705a0ef519873f87f01",
            "d784e68d8cdd46b4bb58b98f0dcb4095",
            "eaec22514805489b8d91b27fe641ec97",
            "bc4f2df6d5954c129f972bbdf96053c2",
            "5073075cd9b14aa5b474271995eece60",
            "ec73e1fb7ad846d9bf87d530b4349d75",
            "dff88c960c814a2c8c2b688d86c0d9bd",
            "f2c8ebe41e274cf08ace0fdf497ad729",
            "2a532b9604434cd18dc81786fd136601",
            "88d709e5331d41b79d9a8605b0a908dc",
            "e499eee302864c54b10773616baf2975",
            "684d90f8c58843979933061a397e7e20",
            "671d8e35ca3c4927a4a3f8be18e2442e",
            "7ce651f8cc2b40099feba946eb174717",
            "92a92404b90242e2aecf33ac3fdc8205",
            "2d83c88b7386461a932cb6d7c3a5209e",
            "729fdeb2d34f4e9ab4f2e8f3c0120002",
            "24a2a47c58024ed5b586ea71436ed2e9",
            "886d7ac9419649558e1f51b075ddadbc",
            "5b64cadbdddf46038f1ec586006dca25",
            "77dd02d3d16b457db33346270722e6fd",
            "5664631d942742e5a7220466032af48f",
            "5d787d0918aa48c6a8c39893ee30c2da",
            "54b8b383bb604fbc8f05058e65882ed1",
            "8ce66b678047448c94e454db1dbeca25",
            "12ec619a416049e8984811ade2d1a328",
            "6611360954b24dd5b9ed3bb98f69c115",
            "90648b5d33c54908b9c411354337be57",
            "3eb7b053136f4fae885aa099bdc3d604",
            "90df9363a3f94a248d4bc8327ee69bf6",
            "4b6614cb29e6401db6bc70a54df2fc7d",
            "a5e67b65250b468ca5372e1694d2b4fb",
            "74702e6a89fb45eea43c5e3ad7d36d3d",
            "a49077b7497241d0ab7b638e5f41bc04",
            "c702caa77db4426b831d98c5c7b96f9d",
            "58ce623418e54b1bbe047ef1f5d313c2",
            "b8af985fb298415a88de4b5785c66437",
            "6cc7a8fe99f448b4b1173ea6ac9a49ed",
            "ade6b09ca6374068936247476a9e7560",
            "c10e66f58d8a4cffab6e173d865a1a91",
            "4be1590e912e47a19bb7e3df4d8ff09d",
            "f2f13632d7d347fd8b1fc9bab78eee7a",
            "9138d1bf91dd422693baf4958bfcb314",
            "b1fbbb0ad26f4cc1b5a338331b38a703",
            "2777539ed4d346f7b670b60ddcb2e892",
            "182ab8151cb04b56afe00a4bc991c72d",
            "9837cbc8716644b1b80b0ee3433f456b",
            "56a983e7eee34137bfbdf6b726fbe0ad",
            "fb9eaa3b7bb64e18b3a46126fbb288a2",
            "c3380ecbfda6467ca57fa0774b6d3e72",
            "3f161bcfa0df4826a7c5530f9569c146",
            "e9f903a33f874fa1afa59b8c52302695",
            "60af517e487b47d1bc73cea98eef7686",
            "6c0ae904f9f84fc3ac0a564b0e47151d",
            "fe04ff836e884203b1ade9c1466a5a52",
            "b850ce2a38aa4d3aa9ea91f9683cea2b",
            "a50c0bf9f8cf4d9382f4686a12b39ec5",
            "1cb2b312029a46988f17250edcfb0aeb",
            "8124a3da753a4a3dafd7e0dc071aa4d4",
            "bccd48c7fa354b7faed03069cf9302dc",
            "37592b6b785446309315509c3379bbb2",
            "235b38e8de104521ae3e486f4e123c13",
            "965c747a6a9042ddbec83801da38aaa4"
          ]
        },
        "id": "gcaF-zuIRW2x",
        "outputId": "bb00e473-b48c-4488-ebeb-86c653e68052"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/971 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f00af10cb8ec4c648bc5f76aee508a06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/431M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a532b9604434cd18dc81786fd136601"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b64cadbdddf46038f1ec586006dca25"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b6614cb29e6401db6bc70a54df2fc7d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2f13632d7d347fd8b1fc9bab78eee7a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "60af517e487b47d1bc73cea98eef7686"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': np.float32(0.9980689),\n",
              "  'word': 'Sylvain',\n",
              "  'start': 11,\n",
              "  'end': 18},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': np.float32(0.94837147),\n",
              "  'word': 'Hugging Face',\n",
              "  'start': 33,\n",
              "  'end': 45},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': np.float32(0.99841917),\n",
              "  'word': 'Brooklyn',\n",
              "  'start': 49,\n",
              "  'end': 57}]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Replace this with your own checkpoint\n",
        "# model_checkpoint = \"huggingface-course/bert-finetuned-ner\"\n",
        "model_checkpoint = \"josteece/bert-finetuned-ner\"\n",
        "token_classifier = pipeline(\n",
        "    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\"\n",
        ")\n",
        "token_classifier(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great! Our model is working as well as the default one for this pipeline!"
      ],
      "metadata": {
        "id": "eEielcyQn6WT"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Token classification (PyTorch)",
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
   
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
